#+TITLE: Chapter 3: Object-Oriented Programming: The Promise and the Reality
#+AUTHOR: Marcus "Spark" Wellington
#+OPTIONS: toc:nil num:t ^:nil

* Chapter 3: Object-Oriented Programming: The Promise and the Reality

#+BEGIN_QUOTE
"I invented the term Object-Oriented, and I can tell you I did not have C++ in mind."
-- Alan Kay
#+END_QUOTE

Few programming paradigms have achieved the mainstream ubiquity of object-oriented programming (OOP). From its origins in the 1960s through its rise to dominance in the 1990s and beyond, OOP has shaped how several generations of programmers conceptualize software design. Corporate training programs, university curricula, and programming books have presented OOP as the natural, intuitive way to structure code. For many developers, objects have become the default unit of computation—a lens through which they instinctively view programming problems.

Yet beneath this apparent consensus lies a profound disconnect. The object-oriented programming practiced by most developers today bears only a passing resemblance to the paradigm as envisioned by its originators. What began as a revolutionary approach to modeling computation as message-passing between independent agents has been transformed into a rigid system of type hierarchies and inheritance trees. In the process, many of the most powerful ideas in the original conception have been lost or distorted, while problematic aspects have been amplified and institutionalized.

This chapter examines both the promise of object-oriented programming—the elegant vision that inspired its creation—and the reality of how it has been realized in mainstream languages and practices. We will explore how this gap emerged, what was lost in the translation, and whether a return to the original vision might offer solutions to problems that continue to plague software development today.

** Simula, Smalltalk, and the Original Vision

The roots of object-oriented programming trace back to Simula, a language developed in the 1960s by Ole-Johan Dahl and Kristen Nygaard at the Norwegian Computing Center. Simula was designed for creating simulations, and its innovation was the concept of objects as representations of real-world entities that could encapsulate both data and the procedures that operated on that data.

Simula introduced several concepts that would become central to object-oriented programming: classes as templates for objects, objects as instances of classes, and inheritance as a mechanism for code reuse and specialization. However, Simula remained firmly within the imperative programming tradition, with objects serving primarily as a structuring mechanism for imperative code.

The more radical vision emerged with Smalltalk, developed at Xerox PARC in the 1970s under the leadership of Alan Kay. Kay's conception of object-oriented programming was deeply influenced by biology, the nascent field of personal computing, and the ARPANET. He envisioned a system of computational "cells" or agents that would communicate exclusively through message passing, maintaining their own internal state but exposing only their interfaces to the outside world.

In Kay's vision, the central idea was not inheritance or classes, but message passing between encapsulated objects. As he later reflected, "The big idea is 'messaging'... The key in making great and growable systems is much more to design how its modules communicate rather than what their internal properties and behaviors should be."

Smalltalk embodied this vision with a remarkably simple and consistent model:

1. Everything is an object, from primitive values like integers to complex structures like windows and processes.
   
2. Objects communicate solely through message passing, not direct invocation of methods or access to internal state.
   
3. Objects respond to messages by executing methods, which are selected dynamically at runtime based on the message and the receiving object.
   
4. New objects are created by sending messages to existing objects (typically, classes).

This model had profound implications. By emphasizing message passing over procedure calls, Smalltalk supported a high degree of polymorphism—different objects could respond to the same message in different ways, determined at runtime. By hiding internal state and implementation details, Smalltalk encouraged loose coupling between components. By allowing method lookup to happen dynamically at runtime, Smalltalk enabled a level of flexibility and extensibility that static languages would struggle to match.

Moreover, Smalltalk was not merely a language but an environment—an integrated system that included graphics, windowing, text editing, and development tools, all implemented as objects communicating through messages. This environment demonstrated the scalability of the object model to complete systems, not just isolated programs.

#+BEGIN_SRC smalltalk :tangle ../examples/smalltalk/chapter03_message_passing.st :mkdirp yes
"A simple example in Smalltalk"
| stack |
stack := OrderedCollection new.  "Creating an object via message passing"
stack add: 'first item'.        "Sending a message with an argument"
stack add: 'second item'.
stack removeLast.               "Another message"
stack isEmpty                   "Query via message"
  ifFalse: [Transcript show: stack first]  "Control flow via message passing"
#+END_SRC

In this example, notice how everything happens through message passing: creating an OrderedCollection by sending "new" to the OrderedCollection class, adding items by sending "add:" messages, removing items with "removeLast", checking conditions with "isEmpty", and even control flow with "ifFalse:". There are no visible method calls in the traditional sense, just objects responding to messages.

Kay's vision was revolutionary—a complete rethinking of how software could be structured, inspired more by biology and systems theory than by the mechanical, procedural thinking that dominated computer science at the time. It promised a more flexible, modular approach to building complex systems, where components could be easily replaced, extended, or repurposed without disrupting the whole.

However, this vision would undergo significant transformation—some would say dilution—as it made its way into mainstream programming practice.

** The Java/C++ Distortion

The widespread adoption of object-oriented programming did not occur through languages like Smalltalk, which embodied Alan Kay's original vision, but through C++ and later Java—languages that retrofitted object-oriented features onto fundamentally imperative foundations.

C++, designed by Bjarne Stroustrup in the early 1980s, began as an extension of C with classes. Its primary goal was to bring object-oriented features to C while maintaining C's performance characteristics and compatibility with existing code. This pragmatic approach led to significant compromises in the object model.

In C++, objects were not the universal computational unit—primitive types, functions, and even global variables existed outside the object system. Message passing was replaced by method calls, which were essentially function calls dispatched through virtual function tables (vtables) when polymorphism was required. Encapsulation was enforced through access modifiers (public, private, protected) rather than the more fundamental information hiding of the Smalltalk model.

Most significantly, C++ emphasized class inheritance as the primary mechanism for code reuse and polymorphism, leading to deep inheritance hierarchies and complex class relationships. This emphasis was partly driven by the limitations of static typing and compile-time binding, which made the dynamic message passing of Smalltalk difficult to implement efficiently.

Java, emerging in the mid-1990s, refined the C++ approach but maintained many of its fundamental assumptions. While Java eliminated some of C++'s complexities (multiple inheritance, manual memory management), it reinforced the centrality of class hierarchies and static typing. Java added interfaces to mitigate some of the limitations of single inheritance, but this was a partial solution that still pushed developers toward thinking in terms of type relationships rather than message protocols.

The contrast between the original vision and its mainstream realization can be seen in a simple example. Here's a typical Java class definition:

#+BEGIN_SRC java :tangle ../examples/java/chapter03_account.java :mkdirp yes
public class Account {
    private double balance;
    
    public Account(double initialBalance) {
        this.balance = initialBalance;
    }
    
    public void deposit(double amount) {
        if (amount > 0) {
            balance += amount;
        }
    }
    
    public boolean withdraw(double amount) {
        if (amount > 0 && balance >= amount) {
            balance -= amount;
            return true;
        }
        return false;
    }
    
    public double getBalance() {
        return balance;
    }
}
#+END_SRC

In this code, we see several departures from the original object-oriented vision:

1. The focus is on the internal state and behavior of the Account class, not on the messages it can receive.
   
2. Methods are directly invoked, not dynamically dispatched based on messages.
   
3. Visibility modifiers (public, private) are used to control access, rather than relying on message protocols.
   
4. The class explicitly declares its interface through method signatures, rather than implicitly through its response to messages.

These may seem like subtle distinctions, but they lead to very different programming styles and system architectures. The Java/C++ approach encourages developers to think in terms of class taxonomies—hierarchies of increasingly specialized types. This "is-a" thinking (a savings account "is an" account, which "is a" financial instrument) produces the infamous inheritance hierarchies that have become synonymous with OOP in many developers' minds.

The widespread adoption of UML (Unified Modeling Language) in the 1990s further cemented this class-centric view, with its emphasis on class diagrams showing inheritance relationships. Design books and training materials taught that good object-oriented design meant identifying the "nouns" in a problem domain and turning them into classes, then identifying "verbs" and turning them into methods—a vast oversimplification that missed the essence of object thinking.

This distortion was not merely a matter of language design; it reflected deeper assumptions about programming and program structure. The Java/C++ model aligned well with corporate needs for standardization, code reuse through libraries, and the ability to enforce architectural decisions through type systems. It felt familiar to developers coming from procedural languages, requiring less of a conceptual leap than the more radical Smalltalk model.

But in focusing on classes, inheritance, and static typing, mainstream OOP lost sight of the more powerful ideas in Kay's original vision: the flexibility of dynamic message passing, the simplicity of a uniform object model, and the emphasis on communication patterns over taxonomic relationships.

** Inheritance versus Composition

The distortion of object-oriented programming from its original vision is perhaps most evident in the over-reliance on inheritance as a code reuse mechanism. Inheritance—the ability of a subclass to inherit fields and methods from a superclass—was present in early object-oriented languages like Simula and Smalltalk, but it was just one tool among many, not the defining feature of the paradigm.

In mainstream OOP as practiced in Java, C++, and similar languages, inheritance became the primary mechanism for code reuse and polymorphism. This led to the deep class hierarchies that many developers now associate with OOP—complex trees of increasingly specialized types, each inheriting from and extending its parent classes.

These inheritance hierarchies create severe maintenance problems:

1. *The Fragile Base Class Problem*: Changes to a base class can unexpectedly break subclasses, even when those changes appear to preserve the class's contract. This fragility arises because inheritance exposes implementation details that subclasses may depend on.

2. *Tight Coupling*: Inheritance creates the strongest possible coupling between classes. Subclasses are intimately dependent on the implementation details of their parent classes, making changes difficult and error-prone.

3. *Inflexibility*: Inheritance relationships are fixed at compile time and cannot be changed dynamically. A class can inherit from only one superclass (in languages with single inheritance) or a fixed set of superclasses (in languages with multiple inheritance).

4. *The Diamond Problem*: In languages with multiple inheritance, ambiguity can arise when a class inherits from two classes that both inherit from a common ancestor, leading to complex resolution rules.

Consider this classic example of inheritance gone wrong:

#+BEGIN_SRC java :tangle ../examples/java/chapter03_square_rectangle.java :mkdirp yes
// The infamous Square/Rectangle problem
class Rectangle {
    protected int width;
    protected int height;
    
    public void setWidth(int width) {
        this.width = width;
    }
    
    public void setHeight(int height) {
        this.height = height;
    }
    
    public int area() {
        return width * height;
    }
}

class Square extends Rectangle {
    // A square must maintain equal width and height
    @Override
    public void setWidth(int width) {
        this.width = width;
        this.height = width;
    }
    
    @Override
    public void setHeight(int height) {
        this.width = height;
        this.height = height;
    }
}
#+END_SRC

This seems reasonable from a taxonomic perspective—a square is a rectangle with equal sides. But it violates the Liskov Substitution Principle (LSP), which states that objects of a subclass should be usable anywhere the superclass is expected without changing the correctness of the program. If client code expects to be able to set the width and height of a rectangle independently, it will behave incorrectly when given a Square.

The alternative to inheritance is composition—building objects by combining simpler objects rather than inheriting from other classes. This approach, often summarized as "favor composition over inheritance," has gained popularity as the limitations of inheritance have become more apparent.

Here's how the Rectangle/Square problem might be addressed using composition:

#+BEGIN_SRC java :tangle ../examples/java/chapter03_composition.java :mkdirp yes
interface Shape {
    int area();
}

class Rectangle implements Shape {
    private int width;
    private int height;
    
    public Rectangle(int width, int height) {
        this.width = width;
        this.height = height;
    }
    
    public void setWidth(int width) {
        this.width = width;
    }
    
    public void setHeight(int height) {
        this.height = height;
    }
    
    public int area() {
        return width * height;
    }
}

class Square implements Shape {
    private int side;
    
    public Square(int side) {
        this.side = side;
    }
    
    public void setSide(int side) {
        this.side = side;
    }
    
    public int area() {
        return side * side;
    }
}
#+END_SRC

With this approach, Square and Rectangle are separate classes that both implement the Shape interface, without any inheritance relationship between them. This better reflects the reality that squares and rectangles have different behavioral contracts, despite their geometric relationship.

Composition offers several advantages over inheritance:

1. *Flexibility*: Composed objects can change their component objects at runtime, allowing for more dynamic behavior.
   
2. *Loose Coupling*: Components interact through well-defined interfaces rather than implementation details, reducing dependencies.
   
3. *Simplicity*: Composed objects typically have simpler interfaces and behavior than complex class hierarchies.
   
4. *Testability*: Components can be tested in isolation, and mock objects can be easily substituted for testing.

The "favor composition over inheritance" guideline has become increasingly accepted in the object-oriented community, reflecting a belated recognition of the limitations of inheritance-centric design. Design patterns like Decorator, Strategy, and Composite provide standard approaches to using composition effectively.

This shift away from inheritance aligns with Alan Kay's original emphasis on message passing rather than class relationships. In a message-passing model, what matters is not the class hierarchy but whether an object can respond appropriately to the messages it receives—a view more compatible with composition and interface-based design than with deep inheritance hierarchies.

** Static versus Dynamic Dispatch

Another fundamental divergence between the original vision of object-oriented programming and its mainstream realization lies in the mechanism of method dispatch—how the system determines which code to execute in response to a method call or message send.

In Alan Kay's original conception, emphasizing message passing, the binding of messages to methods would happen dynamically at runtime. An object would receive a message and determine how to respond to it based on its current state and capabilities. This dynamic binding allowed for extreme flexibility—objects could delegate messages to other objects, transform messages before responding to them, or even respond to messages they weren't explicitly designed to handle.

Smalltalk embodied this approach with its dynamic message dispatch. When an object received a message, the system would search the method dictionary of the object's class (and its superclasses if necessary) to find a matching method. This search happened at runtime, allowing for late binding and dynamic polymorphism.

In contrast, mainstream object-oriented languages like Java and C++ rely primarily on static dispatch, determined at compile time. In these languages, the compiler resolves most method calls based on the declared type of the object, not its actual runtime type. Dynamic dispatch (through virtual methods in C++ or non-final methods in Java) is available, but it's constrained by the static type system and class hierarchies.

Consider this example in Java:

#+BEGIN_SRC java :tangle ../examples/java/chapter03_dispatch.java :mkdirp yes
// Static vs. dynamic dispatch in Java
class Animal {
    public void makeSound() {
        System.out.println("Some generic animal sound");
    }
    
    public void eat() {
        System.out.println("Animal eating");
    }
}

class Dog extends Animal {
    @Override
    public void makeSound() {
        System.out.println("Woof!");
    }
    
    public void fetch() {
        System.out.println("Dog fetching");
    }
}

public class Main {
    public static void main(String[] args) {
        Animal animal = new Dog();  // Dog object, Animal reference
        
        // Dynamic dispatch - calls Dog's implementation
        animal.makeSound();  // Output: "Woof!"
        
        // Static dispatch - Animal reference can't see Dog-specific methods
        // animal.fetch();  // Compilation error
    }
}
#+END_SRC

In this example, the `makeSound()` method is dynamically dispatched—the actual method called depends on the runtime type of the object (Dog). But the `fetch()` method is not visible through the Animal reference, because static typing prevents access to methods not declared in the reference type.

This constraint reflects a fundamental limitation of static typing in traditional object-oriented languages: an object's capabilities are limited by its declared type, not its actual abilities. This contradicts the spirit of Kay's vision, where objects should be able to respond to any message they understand, regardless of their nominal type.

Dynamic languages like Ruby, Python, and JavaScript preserve more of the original message-passing model with their "duck typing" approach—if an object has a method that matches a message, it can respond to that message, regardless of its class or type. This allows for more flexible and adaptable code, at the cost of some compile-time safety guarantees.

#+BEGIN_SRC ruby :tangle ../examples/ruby/chapter03_duck_typing.rb :mkdirp yes
# Duck typing in Ruby
class Duck
  def quack
    puts "Quack!"
  end
  
  def swim
    puts "Swimming like a duck"
  end
end

class Person
  def quack
    puts "I'm imitating a duck!"
  end
  
  def swim
    puts "Swimming like a human"
  end
end

def make_it_quack(object)
  object.quack  # Will work with any object that responds to 'quack'
end

duck = Duck.new
person = Person.new

make_it_quack(duck)    # Output: "Quack!"
make_it_quack(person)  # Output: "I'm imitating a duck!"
#+END_SRC

In this Ruby example, the `make_it_quack` method works with any object that can respond to the `quack` message, without requiring a common superclass or interface. This is closer to Kay's original conception of objects as autonomous entities that communicate through messages.

The trade-off between static and dynamic dispatch is not merely a technical detail—it reflects fundamentally different views of what object-oriented programming is about. Is it about building rigid type hierarchies with strong compile-time guarantees, or about creating flexible networks of communicating objects that can adapt to new requirements at runtime?

The mainstream adoption of static typing and limited dynamic dispatch in languages like Java and C++ has pushed object-oriented programming toward the former view, losing much of the flexibility and adaptability that were central to Kay's original vision. While this approach has benefits for certain kinds of systems—particularly large-scale enterprise applications where type safety and explicit interfaces are valued—it has also constrained the paradigm's potential and contributed to many of the design problems associated with OOP today.

** Objects as Universal Abstraction: Dream or Delusion?

Alan Kay's vision of object-oriented programming posited objects as a universal abstraction—a fundamental unit of computation that could represent everything from primitive values to complex systems. In Smalltalk, this vision was realized: everything was an object, from numbers and strings to classes and methods themselves. This uniformity created an elegant, consistent model where the same mechanisms (message passing, encapsulation) applied at all levels of the system.

This idea of objects as a universal abstraction promised several advantages:

1. *Conceptual Simplicity*: A single model—objects communicating through messages—could explain computation at every level, from the most primitive operations to the most complex system behaviors.

2. *Recursive Composition*: Objects could contain other objects, which could contain other objects, allowing for complex structures to be built from simple components in a consistent way.

3. *Uniform Extension*: New capabilities could be added to the system by creating new objects that communicated through the same message-passing mechanisms as existing objects.

4. *Emergent Behavior*: Complex system behavior could emerge from the interactions of simpler objects, each following its own rules.

However, mainstream object-oriented languages abandoned this vision of universal objects. In Java and C++, objects coexist with primitive types, static methods, procedural code, and other non-object constructs. This hybrid approach created a more complex mental model, where different rules apply to different parts of the system.

The question is whether the universal object model was a beautiful dream that couldn't work in practice, or whether we've deluded ourselves into accepting a compromised version of object-oriented programming that falls far short of its potential.

Arguments against the universal object model include:

1. *Performance Concerns*: Representing everything as objects, with dynamic method dispatch for all operations, would impose performance penalties that many applications couldn't afford.

2. *Complexity Overhead*: Simple operations like adding two numbers shouldn't require the full machinery of object message passing, with its associated allocation and dispatch costs.

3. *Mental Overhead*: Thinking of absolutely everything as objects might impose unnecessary cognitive load for certain problems that are naturally expressed in other ways.

4. *Practical Constraints*: Hardware architectures and operating systems are not object-oriented, creating impedance mismatches for pure object systems.

These practical concerns, especially on the resource-constrained hardware of the 1980s and 1990s, drove the compromises we see in mainstream OOP languages. But defenders of the pure object model might counter:

1. *Performance is a Moving Target*: Hardware has advanced dramatically since these design decisions were made, potentially making the performance concerns less relevant.

2. *Just-In-Time Compilation*: Modern JIT compilers can optimize dynamic dispatch to approach the performance of static binding in many cases.

3. *Conceptual Benefits*: The elegance and consistency of a universal object model might outweigh the performance costs for many applications, especially given today's emphasis on developer productivity over raw performance.

4. *Successful Examples*: Systems like Smalltalk, Self, and to some extent modern JavaScript engines demonstrate that universal object models can work in practice.

The debate between these viewpoints remains unresolved. What is clear is that the mainstream adoption of object-oriented programming involved significant compromises to the original vision, producing a hybrid paradigm that incorporates elements of object thinking alongside procedural, functional, and even assembly-like constructs.

This hybrid nature may well be a strength rather than a weakness—a pragmatic adaptation of the pure model to the messy realities of computing. But it's important to recognize that what most programmers think of as "object-oriented programming" today bears only a passing resemblance to Kay's original conception.

The universal object model remains an intriguing alternative—a road not fully traveled in mainstream programming, but one that continues to influence language design and systems thinking. Languages like Pharo (a modern Smalltalk), Ruby, and even JavaScript preserve more of this universal object vision than statically typed languages like Java and C++, suggesting that the dream is not entirely dead, just realized in different corners of the programming ecosystem.

** Conclusion

Object-oriented programming embodies one of the great paradoxes in the history of programming languages: a paradigm simultaneously considered a dramatic success and a profound disappointment. Its success is evident in its widespread adoption across domains, industries, and decades. Its disappointment lies in how far the mainstream practice has diverged from the elegant, powerful vision that inspired its creation.

The original conception of OOP—with its emphasis on message passing, uniform object model, and dynamic behavior—offered a radical rethinking of software structure. It promised systems composed of autonomous, encapsulated components that could be recombined and extended with minimal friction. It envisioned software that would grow and evolve naturally, like biological systems, rather than being constructed and maintained through increasingly complex engineering processes.

What emerged in mainstream practice was quite different: a static, class-centric model that often produced brittle inheritance hierarchies, tight coupling, and rigid designs. The focus shifted from communication protocols to type relationships, from dynamic message passing to static method binding, from adaptive objects to fixed class hierarchies.

This divergence was not merely a technical evolution but a fundamental shift in philosophy—from objects as autonomous computational agents to objects as instances of taxonomic categories. It represented, in many ways, a retreat from the more radical implications of Kay's vision back toward the familiar territory of procedural programming with added structure.

Yet the story of object-oriented programming is not a simple tale of promise and betrayal. The mainstream adoption of OOP, even in its compromised form, brought significant benefits:

1. It encouraged thinking about data and behavior together, challenging the procedure-centric view of earlier paradigms.
   
2. It promoted encapsulation and information hiding as fundamental design principles, improving modularity in large systems.
   
3. It provided a vocabulary and set of patterns for discussing software design at a higher level of abstraction than procedural code.
   
4. It enabled the creation of reusable libraries and frameworks that have accelerated software development across the industry.

Moreover, the pendulum may be swinging back toward aspects of the original vision. Modern design advice like "favor composition over inheritance," "program to an interface, not an implementation," and "prefer immutability" addresses many of the problems that arose from the class-centric distortion of OOP. Dynamic languages like Ruby and Python preserve more of the message-passing model, while functional-object hybrids like Scala incorporate lessons from both paradigms.

The critical insight that emerges from this historical arc is that paradigms are not monolithic entities but complex webs of ideas, some of which may be realized while others are abandoned or distorted. The "object-oriented programming" practiced today is neither a complete fulfillment nor a complete abandonment of Kay's vision—it's a complex evolution shaped by technical constraints, market forces, and human psychology.

As we consider the future of programming paradigms, the lessons of OOP's journey suggest caution about both revolutionary claims and dismissive critiques. The most interesting developments may lie not in pure paradigms but in thoughtful syntheses that draw from multiple traditions—including both the mainstream practice of OOP and its original, more radical vision.

In the next chapter, we'll explore a paradigm that took a very different approach to abstraction and composition: logic programming, which separated the "what" from the "how" more dramatically than perhaps any other major paradigm. Like object-oriented programming, logic programming contained powerful ideas that have been only partially realized in mainstream practice—another case of paradigms lost and, perhaps, waiting to be rediscovered.

#+BEGIN_QUOTE
"The best way to predict the future is to invent it."
-- Alan Kay
#+END_QUOTE